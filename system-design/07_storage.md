# Storage Systems

Storage systems form the backbone of modern applications. Understanding different storage types and when to use them is critical for system design.

---

## ğŸ“¦ Storage Types Overview

| Type | Use Case | Examples | Access Pattern |
|------|----------|----------|----------------|
| **Block Storage** | Databases, VMs | EBS, SAN | Low-level, high performance |
| **Object Storage** | Media, backups | S3, Blob Storage | HTTP API, scalable |
| **File Storage** | Shared files | EFS, NFS | File system interface |
| **Database** | Structured data | PostgreSQL, MongoDB | Query language |
| **Cache** | Hot data | Redis, Memcached | Key-value, in-memory |

---

## ğŸ—„ï¸ Block Storage

Block storage divides data into fixed-size blocks. Each block has a unique address. The OS treats it as a hard drive.

### Characteristics

**Performance:**
- âœ… Low latency (< 10ms)
- âœ… High IOPS (10,000+ operations/sec)
- âœ… Consistent performance

**Use Cases:**
- Databases (MySQL, PostgreSQL)
- Virtual machines
- High-performance applications

**Examples:**
- AWS EBS (Elastic Block Store)
- Azure Disk Storage
- GCP Persistent Disks
- Physical SAN/NAS

### Block Storage Types

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Block Storage Types         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  HDD (Hard Disk Drive)              â”‚
â”‚  â€¢ Magnetic spinning disks          â”‚
â”‚  â€¢ 100-200 IOPS                     â”‚
â”‚  â€¢ Low cost ($0.045/GB/month)       â”‚
â”‚  â€¢ Use: Backups, logs               â”‚
â”‚                                     â”‚
â”‚  SSD (Solid State Drive)            â”‚
â”‚  â€¢ Flash memory                     â”‚
â”‚  â€¢ 3,000-16,000 IOPS                â”‚
â”‚  â€¢ Medium cost ($0.10/GB/month)     â”‚
â”‚  â€¢ Use: General purpose databases   â”‚
â”‚                                     â”‚
â”‚  Provisioned IOPS SSD               â”‚
â”‚  â€¢ Guaranteed performance           â”‚
â”‚  â€¢ Up to 64,000 IOPS                â”‚
â”‚  â€¢ High cost ($0.125/GB/month)      â”‚
â”‚  â€¢ Use: High-traffic databases      â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Database Setup

```python
# Mount EBS volume to EC2 instance
# 1. Attach volume in AWS console
# 2. Format and mount

import subprocess

def setup_database_storage():
    # Format volume
    subprocess.run(['mkfs', '-t', 'ext4', '/dev/xvdf'])
    
    # Create mount point
    subprocess.run(['mkdir', '-p', '/data/mysql'])
    
    # Mount
    subprocess.run(['mount', '/dev/xvdf', '/data/mysql'])
    
    # Add to /etc/fstab for auto-mount on boot
    with open('/etc/fstab', 'a') as f:
        f.write('/dev/xvdf  /data/mysql  ext4  defaults,nofail  0  2\n')
```

**RAID Configurations:**

```
RAID 0 (Striping):
  â€¢ Data split across disks
  â€¢ 2x performance
  â€¢ 0 redundancy (one disk fails = data loss)
  
RAID 1 (Mirroring):
  â€¢ Data copied to multiple disks
  â€¢ Redundancy (can lose 1 disk)
  â€¢ No performance gain
  
RAID 10 (1+0):
  â€¢ Combination of striping and mirroring
  â€¢ High performance + redundancy
  â€¢ Requires 4+ disks
```

---

## â˜ï¸ Object Storage

Object storage stores data as objects with metadata. Accessed via HTTP API. Infinitely scalable.

### Characteristics

**Scalability:**
- âœ… Unlimited storage
- âœ… Automatic scaling
- âœ… No capacity planning

**Durability:**
- âœ… 99.999999999% (11 9's) durability
- âœ… Automatic replication
- âœ… Versioning

**Use Cases:**
- Media files (images, videos)
- Backups and archives
- Static website hosting
- Data lakes

**Examples:**
- AWS S3
- Azure Blob Storage
- Google Cloud Storage
- MinIO (self-hosted)

### Object Structure

```
Object = Data + Metadata + Unique Key

Example:
  Key: /users/123/profile.jpg
  Data: <binary image data>
  Metadata:
    - Content-Type: image/jpeg
    - Content-Length: 245678
    - Last-Modified: 2024-01-15T10:00:00Z
    - Custom: user-id=123, uploaded-by=app
```

### S3 Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           S3 Bucket: my-app            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚  /images/                              â”‚
â”‚    â”œâ”€â”€ product-1.jpg                   â”‚
â”‚    â”œâ”€â”€ product-2.jpg                   â”‚
â”‚    â””â”€â”€ user-avatar-123.png             â”‚
â”‚                                        â”‚
â”‚  /videos/                              â”‚
â”‚    â”œâ”€â”€ tutorial-1.mp4                  â”‚
â”‚    â””â”€â”€ demo.mp4                        â”‚
â”‚                                        â”‚
â”‚  /backups/                             â”‚
â”‚    â”œâ”€â”€ db-backup-2024-01-15.sql.gz     â”‚
â”‚    â””â”€â”€ logs-2024-01-14.tar.gz          â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Access:
  https://my-app.s3.amazonaws.com/images/product-1.jpg
```

### Using S3 (Python)

```python
import boto3
from botocore.exceptions import ClientError

s3 = boto3.client('s3')

# Upload file
def upload_file(file_path, bucket, object_key):
    try:
        s3.upload_file(
            file_path,
            bucket,
            object_key,
            ExtraArgs={
                'ContentType': 'image/jpeg',
                'Metadata': {
                    'uploaded-by': 'user-123',
                    'original-name': 'vacation.jpg'
                }
            }
        )
        print(f"Uploaded: {object_key}")
    except ClientError as e:
        print(f"Error: {e}")

# Download file
def download_file(bucket, object_key, file_path):
    s3.download_file(bucket, object_key, file_path)

# Generate presigned URL (temporary access)
def generate_presigned_url(bucket, object_key, expiration=3600):
    url = s3.generate_presigned_url(
        'get_object',
        Params={'Bucket': bucket, 'Key': object_key},
        ExpiresIn=expiration  # 1 hour
    )
    return url

# List objects
def list_objects(bucket, prefix=''):
    response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)
    for obj in response.get('Contents', []):
        print(f"{obj['Key']} - {obj['Size']} bytes")

# Delete object
def delete_object(bucket, object_key):
    s3.delete_object(Bucket=bucket, Key=object_key)
```

### S3 Storage Classes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              S3 Storage Classes                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  Standard (Default)                                  â”‚
â”‚  â€¢ Frequently accessed data                          â”‚
â”‚  â€¢ $0.023/GB/month                                   â”‚
â”‚  â€¢ 99.99% availability                               â”‚
â”‚                                                      â”‚
â”‚  Intelligent-Tiering                                 â”‚
â”‚  â€¢ Automatic cost optimization                       â”‚
â”‚  â€¢ Moves between tiers based on access              â”‚
â”‚  â€¢ $0.023/GB/month + $0.0025/1000 objects           â”‚
â”‚                                                      â”‚
â”‚  Infrequent Access (IA)                              â”‚
â”‚  â€¢ Accessed less than once a month                   â”‚
â”‚  â€¢ $0.0125/GB/month + retrieval fee                  â”‚
â”‚  â€¢ 99.9% availability                                â”‚
â”‚                                                      â”‚
â”‚  Glacier (Archive)                                   â”‚
â”‚  â€¢ Long-term archive (retrieval: mins to hours)      â”‚
â”‚  â€¢ $0.004/GB/month                                   â”‚
â”‚  â€¢ Use: Backups, compliance                          â”‚
â”‚                                                      â”‚
â”‚  Glacier Deep Archive                                â”‚
â”‚  â€¢ Lowest cost (retrieval: 12-48 hours)              â”‚
â”‚  â€¢ $0.00099/GB/month                                 â”‚
â”‚  â€¢ Use: 7-10 year retention                          â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Lifecycle Policies

Automatically transition objects between storage classes:

```python
lifecycle_policy = {
    'Rules': [
        {
            'Id': 'Move old logs to IA',
            'Status': 'Enabled',
            'Prefix': 'logs/',
            'Transitions': [
                {
                    'Days': 30,
                    'StorageClass': 'STANDARD_IA'
                },
                {
                    'Days': 90,
                    'StorageClass': 'GLACIER'
                }
            ],
            'Expiration': {
                'Days': 365  # Delete after 1 year
            }
        }
    ]
}

s3.put_bucket_lifecycle_configuration(
    Bucket='my-bucket',
    LifecycleConfiguration=lifecycle_policy
)
```

### Multipart Upload (Large Files)

For files > 100 MB:

```python
def multipart_upload(file_path, bucket, object_key):
    # Initiate multipart upload
    response = s3.create_multipart_upload(
        Bucket=bucket,
        Key=object_key
    )
    upload_id = response['UploadId']
    
    # Upload parts (5 MB each)
    part_size = 5 * 1024 * 1024  # 5 MB
    parts = []
    
    with open(file_path, 'rb') as f:
        part_number = 1
        while True:
            data = f.read(part_size)
            if not data:
                break
            
            # Upload part
            response = s3.upload_part(
                Bucket=bucket,
                Key=object_key,
                PartNumber=part_number,
                UploadId=upload_id,
                Body=data
            )
            
            parts.append({
                'PartNumber': part_number,
                'ETag': response['ETag']
            })
            part_number += 1
    
    # Complete upload
    s3.complete_multipart_upload(
        Bucket=bucket,
        Key=object_key,
        UploadId=upload_id,
        MultipartUpload={'Parts': parts}
    )
```

**Benefits:**
- âœ… Upload large files (up to 5 TB)
- âœ… Resume on failure
- âœ… Parallel uploads (faster)

---

## ğŸ“ File Storage

File storage provides a file system interface (folders, files). Shared across multiple servers.

### Characteristics

**Access:**
- âœ… POSIX-compliant file system
- âœ… Hierarchical structure (folders)
- âœ… Concurrent access from multiple servers

**Use Cases:**
- Shared application files
- Content management systems
- Web servers (multiple instances)
- Big data analytics

**Examples:**
- AWS EFS (Elastic File System)
- Azure Files
- Google Filestore
- NFS (Network File System)

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web     â”‚      â”‚  Web     â”‚      â”‚  Web     â”‚
â”‚ Server 1 â”‚      â”‚ Server 2 â”‚      â”‚ Server 3 â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                 â”‚                 â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                 â”‚
              â–¼                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  EFS (Shared Storage)    â”‚
        â”‚  /var/www/uploads/       â”‚
        â”‚  /var/www/static/        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Using EFS

```bash
# Mount EFS on EC2 instances
# 1. Install NFS client
sudo yum install -y nfs-utils

# 2. Create mount point
sudo mkdir -p /mnt/efs

# 3. Mount EFS
sudo mount -t nfs4 -o nfsvers=4.1 \
  fs-12345678.efs.us-east-1.amazonaws.com:/ /mnt/efs

# 4. Auto-mount on boot (add to /etc/fstab)
echo "fs-12345678.efs.us-east-1.amazonaws.com:/ /mnt/efs nfs4 defaults,_netdev 0 0" | sudo tee -a /etc/fstab
```

```python
# Application using shared storage
def upload_file(file):
    # All web servers write to same location
    file_path = f'/mnt/efs/uploads/{file.filename}'
    file.save(file_path)
    
    return f'https://cdn.example.com/uploads/{file.filename}'

def serve_file(filename):
    # All web servers can read from same location
    file_path = f'/mnt/efs/uploads/{filename}'
    return send_file(file_path)
```

---

## ğŸŒ Content Delivery Network (CDN)

CDNs cache and serve static content from edge locations close to users.

### Architecture

```
User in Tokyo                  User in New York
     â”‚                              â”‚
     â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CDN    â”‚                    â”‚  CDN    â”‚
â”‚  Edge   â”‚                    â”‚  Edge   â”‚
â”‚  Tokyo  â”‚                    â”‚New York â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Cache MISS
                 â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Origin   â”‚
           â”‚  Server   â”‚
           â”‚  (S3)     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How CDN Works

```
1. User requests: https://cdn.example.com/images/logo.png

2. DNS resolves to nearest CDN edge location

3. CDN checks cache:
   â€¢ HIT: Return cached file (fast!)
   â€¢ MISS: Fetch from origin, cache, return

4. Subsequent requests served from cache (< 10ms)
```

### CDN Benefits

```
Without CDN:
  User (Tokyo) â†’ Origin (US West) â†’ 200ms latency
  
With CDN:
  User (Tokyo) â†’ CDN Edge (Tokyo) â†’ 10ms latency
  
Benefits:
  âœ… Faster load times (10-20x)
  âœ… Reduced origin load (90% served from cache)
  âœ… DDoS protection (distributed)
  âœ… Lower bandwidth costs
```

### CloudFront Configuration

```python
import boto3

cloudfront = boto3.client('cloudfront')

# Create CDN distribution
distribution_config = {
    'Origins': {
        'Quantity': 1,
        'Items': [{
            'Id': 's3-origin',
            'DomainName': 'my-bucket.s3.amazonaws.com',
            'S3OriginConfig': {
                'OriginAccessIdentity': ''
            }
        }]
    },
    'DefaultCacheBehavior': {
        'TargetOriginId': 's3-origin',
        'ViewerProtocolPolicy': 'redirect-to-https',
        'AllowedMethods': {
            'Quantity': 2,
            'Items': ['GET', 'HEAD']
        },
        'Compress': True,  # Gzip compression
        'MinTTL': 0,
        'DefaultTTL': 86400,  # 24 hours
        'MaxTTL': 31536000    # 1 year
    },
    'Comment': 'CDN for my-app',
    'Enabled': True
}
```

### Cache Control Headers

```python
# Upload to S3 with cache headers
s3.upload_file(
    'logo.png',
    'my-bucket',
    'images/logo.png',
    ExtraArgs={
        'ContentType': 'image/png',
        'CacheControl': 'public, max-age=31536000, immutable',  # 1 year
        'Metadata': {
            'version': '1.0'
        }
    }
)

# Different cache policies:
# Static assets (logo, CSS): max-age=31536000 (1 year)
# HTML: max-age=0, must-revalidate (always check)
# API responses: no-cache (don't cache)
```

### Cache Invalidation

```python
# Invalidate (purge) CDN cache when content changes
def invalidate_cdn_cache(paths):
    cloudfront.create_invalidation(
        DistributionId='E1234567890ABC',
        InvalidationBatch={
            'Paths': {
                'Quantity': len(paths),
                'Items': paths
            },
            'CallerReference': str(time.time())
        }
    )

# Example:
invalidate_cdn_cache(['/images/logo.png', '/css/*'])
```

**Cache Invalidation Strategies:**
```
1. Manual Invalidation:
   â€¢ Slow (15-30 minutes)
   â€¢ Costs money ($0.005 per path after first 1000)
   
2. Versioned URLs (Recommended):
   â€¢ logo.png â†’ logo-v2.png
   â€¢ /static/v1/app.js â†’ /static/v2/app.js
   â€¢ Old version expires naturally
   â€¢ No invalidation needed
   
3. Query String:
   â€¢ logo.png?v=2
   â€¢ logo.png?hash=abc123
```

---

## ğŸ—‚ï¸ Distributed File Systems

For big data and analytics workloads.

### HDFS (Hadoop Distributed File System)

```
Architecture:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NameNode   â”‚  â† Metadata (file locations)
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚DataNode 1â”‚ â”‚DataNode 2â”‚ â”‚DataNode 3â”‚
â”‚ Block 1  â”‚ â”‚ Block 1  â”‚ â”‚ Block 2  â”‚
â”‚ Block 3  â”‚ â”‚ Block 2  â”‚ â”‚ Block 3  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Replication: 3x (default)
Block size: 128 MB (default)
```

**Example:**
```
File: video.mp4 (500 MB)

Split into blocks:
  â€¢ Block 1 (128 MB) â†’ DataNode 1, 2, 3
  â€¢ Block 2 (128 MB) â†’ DataNode 2, 3, 4
  â€¢ Block 3 (128 MB) â†’ DataNode 3, 4, 5
  â€¢ Block 4 (116 MB) â†’ DataNode 4, 5, 1

Benefits:
  âœ… Fault tolerance (3 copies)
  âœ… Parallel processing (MapReduce)
  âœ… Scalable (add more DataNodes)
```

---

## ğŸ’¡ Storage Selection Guide

### Decision Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Storage Decision Tree                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Need: Database storage?                                â”‚
â”‚    â†’ YES: Block Storage (EBS)                           â”‚
â”‚           â€¢ High IOPS, low latency                      â”‚
â”‚           â€¢ Provisioned IOPS for production DBs         â”‚
â”‚                                                         â”‚
â”‚  Need: Media files (images/videos)?                     â”‚
â”‚    â†’ YES: Object Storage (S3)                           â”‚
â”‚           â€¢ Unlimited scale                             â”‚
â”‚           â€¢ + CDN for fast delivery                     â”‚
â”‚           â€¢ Lifecycle policies for archival             â”‚
â”‚                                                         â”‚
â”‚  Need: Shared files across servers?                     â”‚
â”‚    â†’ YES: File Storage (EFS)                            â”‚
â”‚           â€¢ POSIX file system                           â”‚
â”‚           â€¢ Concurrent access                           â”‚
â”‚                                                         â”‚
â”‚  Need: Big data analytics?                              â”‚
â”‚    â†’ YES: Distributed File System (HDFS)                â”‚
â”‚           â€¢ Petabyte scale                              â”‚
â”‚           â€¢ Parallel processing                         â”‚
â”‚                                                         â”‚
â”‚  Need: Fast access to data?                             â”‚
â”‚    â†’ YES: Cache (Redis/Memcached)                       â”‚
â”‚           â€¢ In-memory                                   â”‚
â”‚           â€¢ < 1ms latency                               â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comparison Table

| Requirement | Block | Object | File | Cache |
|-------------|-------|--------|------|-------|
| **Latency** | < 10ms | 50-200ms | 10-50ms | < 1ms |
| **Throughput** | GB/s | MB/s | GB/s | GB/s |
| **Scalability** | TB | PB+ | PB | GB |
| **Cost ($/GB/mo)** | $0.10 | $0.023 | $0.30 | $0.50+ |
| **Durability** | 99.9% | 99.999999999% | 99.99% | None |
| **Use Case** | Databases | Media | Shared files | Hot data |

---

## ğŸ¯ Interview Tips

**Key Points to Cover:**
1. âœ… Block vs Object vs File storage differences
2. âœ… When to use S3 vs EBS vs EFS
3. âœ… CDN benefits and architecture
4. âœ… Storage classes and lifecycle policies
5. âœ… Multipart upload for large files

**Common Questions:**
- "How would you store user profile pictures?" â†’ S3 + CloudFront CDN
- "How would you store 10TB of logs?" â†’ S3 with lifecycle to Glacier
- "Database keeps running out of disk space?" â†’ EBS volume expansion or sharding
- "Slow image loading for global users?" â†’ CDN with edge caching

**Red Flags:**
- âŒ Using block storage for media files (expensive, not scalable)
- âŒ Not using CDN for static content
- âŒ Storing large files in database (BLOB)
- âŒ Not considering storage costs

---

**Next:** [Networking](08_networking.md)
